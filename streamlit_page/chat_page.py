# chat_page.py
def chat_page():
    import sys
    import os
    sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))
    import re
    import warnings
    import json
    import streamlit as st
    from dotenv import load_dotenv
    import openai
    from langchain.prompts import PromptTemplate
    from langchain_openai import ChatOpenAI
    from langchain.callbacks.base import BaseCallbackHandler
    from streamlit_chat import message
    from DB.newsletter import get_newsletter_keywords_by_id

    # 1. ìŠ¤íŠ¸ë¦¬ë° í•¸ë“¤ëŸ¬ ì •ì˜
    class StreamHandler(BaseCallbackHandler):
        def __init__(self, container):
            self.container = container
            self.output = ""

        def on_llm_new_token(self, token: str, **kwargs) -> None:
            self.output += token
            self.container.markdown(self.output)

    # 2. í™˜ê²½ ì„¤ì • ë° ì´ˆê¸°í™”
    load_dotenv()
    warnings.filterwarnings("ignore", category=UserWarning)

    api_key = os.getenv("OPENAI_API_KEY")
    llm = ChatOpenAI(model="gpt-3.5-turbo", temperature=0.7, api_key=api_key, streaming=True)

    prompt_template = PromptTemplate(
        input_variables=["keyword"],
        template="""'{keyword}' í‚¤ì›Œë“œì— ëŒ€í•´ ì‚¬ìš©ìê°€ ChatGPTì— ë¬¼ì–´ë³¼ ìˆ˜ ìˆëŠ” ë‹¤ì–‘í•œ ì§ˆë¬¸ 5ê°œë¥¼ ë§Œë“¤ì–´ì¤˜. 
ê° ë¬¸ì¥ì€ 1ì¤„ë¡œ ëª…í™•í•˜ê²Œ ì‘ì„±í•´ì¤˜.
ì¶œë ¥ í˜•ì‹ì€ ë²ˆí˜¸ ì—†ì´, ì§ˆë¬¸ 5ê°œë¥¼ ì¤„ë°”ê¿ˆìœ¼ë¡œ ë‚˜ì—´í•´ì¤˜."""
    )

    def categorize_keywords_with_gpt(api_key: str, keywords: list[str]) -> dict:
        llm = ChatOpenAI(model="gpt-3.5-turbo", temperature=0.3, api_key=api_key)
        template = PromptTemplate(
            input_variables=["keywords"],
            template="""
            ì•„ë˜ëŠ” ê±´ê°•ê³¼ ì˜í•™ ë¶„ì•¼ í‚¤ì›Œë“œ ëª©ë¡ì…ë‹ˆë‹¤. ì˜ë¯¸ìƒ ìœ ì‚¬í•œ ê²ƒë¼ë¦¬ ë¬¶ì–´ì„œ ì¹´í…Œê³ ë¦¬ ì´ë¦„ì„ ë¶™ì´ê³ , JSON í˜•ì‹ìœ¼ë¡œ ì¶œë ¥í•´ì¤˜.

            í‚¤ì›Œë“œ: {keywords}

            ì¶œë ¥ í˜•ì‹ ì˜ˆì‹œ:
            {{
            "í˜ˆì•¡ ì‘ê³  ê´€ë ¨": ["í˜ˆì „", "ì‘ê³ ", "í˜ˆì†ŒíŒ"],
            "ì§ˆí™˜ ì´ë¦„": ["ë‡Œì¡¸ì¤‘", "ì‹¬ê·¼ê²½ìƒ‰"]
            }}
            """
        )
        chain = template | llm
        response = chain.invoke({"keywords": ", ".join(keywords)})
        try:
            return json.loads(response.content)
        except Exception:
            return {"ê¸°íƒ€": keywords}

    # 3. í‚¤ì›Œë“œ ë¶ˆëŸ¬ì˜¤ê¸° ë° ì¹´í…Œê³ ë¦¬í™”
    newsletter_id = 1
    raw_keywords = get_newsletter_keywords_by_id(newsletter_id)
    keyword_list = []
    if raw_keywords:
        lines = raw_keywords.strip().splitlines()
        for line in lines:
            match = re.match(r"^\d+\.\s*(.+)", line.strip())
            if match:
                keyword_list.append(match.group(1).strip())
    categorized_keywords = categorize_keywords_with_gpt(api_key, keyword_list)
    st.session_state.categorized_keywords = categorized_keywords

    # 4. ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    if "chat_history" not in st.session_state:
        st.session_state.chat_history = []
    if "generated_prompts" not in st.session_state:
        st.session_state.generated_prompts = []
    if "pending_prompt_question" not in st.session_state:
        st.session_state.pending_prompt_question = None
    if "trigger_from_prompt" not in st.session_state:
        st.session_state.trigger_from_prompt = False

    for field, default in [("gender", ""), ("age", ""), ("height", ""), ("weight", "")]:
        if field not in st.session_state:
            st.session_state[field] = default

    # 5. ê±´ê°• ì •ë³´ ì…ë ¥
    with st.expander("ğŸ‘¤ ê±´ê°• ì •ë³´ ì…ë ¥ (ì„ íƒ)"):
        with st.form(key="health_form"):
            gender = st.selectbox("ì„±ë³„", ["", "ë‚¨ì„±", "ì—¬ì„±"], index=["", "ë‚¨ì„±", "ì—¬ì„±"].index(st.session_state.get("gender", "")))
            age = st.text_input("ë‚˜ì´ (ìˆ«ìë§Œ)", value=st.session_state.get("age", ""))
            height = st.text_input("í‚¤ (cm)", value=st.session_state.get("height", ""))
            weight = st.text_input("ëª¸ë¬´ê²Œ (kg)", value=st.session_state.get("weight", ""))

            submitted = st.form_submit_button("âœ… ì €ì¥í•˜ê¸°")
            if submitted:
                st.session_state["gender"] = gender
                st.session_state["age"] = age
                st.session_state["height"] = height
                st.session_state["weight"] = weight
                st.success("ê±´ê°• ì •ë³´ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")


    def get_health_context():
        return f"ì‚¬ìš©ì ì •ë³´: ì„±ë³„={st.session_state.gender}, ë‚˜ì´={st.session_state.age}ì„¸, í‚¤={st.session_state.height}cm, ëª¸ë¬´ê²Œ={st.session_state.weight}kg"

    # 6. UI ë° ì§ˆë¬¸ íë¦„
    st.title("í‚¤ì›Œë“œ ê¸°ë°˜ í”„ë¡¬í”„íŠ¸ & ê±´ê°• ì±—ë´‡")

    if st.session_state.get("categorized_keywords"):
        st.markdown("### ğŸ” í‚¤ì›Œë“œë¥¼ í´ë¦­í•´ ì§ˆë¬¸ ì˜ˆì‹œë¥¼ ìƒì„±í•˜ì„¸ìš”")
        for category, words in st.session_state.categorized_keywords.items():
            with st.expander(f"ğŸ“‚ {category}"):
                kw_cols = st.columns(4)
                for i, kw in enumerate(words):
                    if kw_cols[i % 4].button(kw, key=f"kw_btn_{category}_{i}"):
                        chain = prompt_template | llm
                        with st.spinner(f"'{kw}' í‚¤ì›Œë“œë¡œ ì§ˆë¬¸ ì˜ˆì‹œ ìƒì„± ì¤‘..."):
                            response = chain.invoke({"keyword": kw})
                            prompts = response.content.strip().split("\n")
                            st.session_state.generated_prompts = [p.strip() for p in prompts if p.strip()]

    prompts = st.session_state.get("generated_prompts", [])
    if prompts:
        st.markdown("### ğŸ’¡ í”„ë¡¬í”„íŠ¸ë¥¼ í´ë¦­í•˜ë©´ ì•„ë˜ì—ì„œ ë‹µë³€ì„ ë°›ì„ ìˆ˜ ìˆì–´ìš”")
        cols = st.columns(2)
        for idx, prompt in enumerate(prompts):
            if cols[idx % 2].button(prompt):
                st.session_state.pending_prompt_question = prompt
                st.session_state.trigger_from_prompt = True
                st.rerun()

    st.markdown("### âœï¸ ì§ì ‘ ì§ˆë¬¸í•˜ê¸°")
    user_input = st.text_input("ì§ˆë¬¸ì„ ì…ë ¥í•´ë³´ì„¸ìš”", key="direct_input")
    if st.button("ë‹µë³€ ë°›ê¸°", key="direct_submit") and user_input.strip():
        context = get_health_context()
        full_prompt = context + "\nì§ˆë¬¸: " + user_input.strip()
        with st.spinner("ë‹µë³€ ìƒì„± ì¤‘..."):
            placeholder = st.empty()
            handler = StreamHandler(placeholder)
            llm_with_stream = ChatOpenAI(
                model="gpt-3.5-turbo",
                temperature=0.7,
                api_key=api_key,
                streaming=True,
                callbacks=[handler],
            )
            response = llm_with_stream.invoke(full_prompt)
            st.session_state.chat_history.append((user_input.strip(), response.content))

    if st.session_state.trigger_from_prompt and st.session_state.pending_prompt_question:
        context = get_health_context()
        prompt_question = st.session_state.pending_prompt_question
        full_prompt = context + "\nì§ˆë¬¸: " + prompt_question
        with st.spinner("ë‹µë³€ ìƒì„± ì¤‘..."):
            placeholder = st.empty()
            handler = StreamHandler(placeholder)
            llm_with_stream = ChatOpenAI(
                model="gpt-3.5-turbo",
                temperature=0.7,
                api_key=api_key,
                streaming=True,
                callbacks=[handler],
            )
            response = llm_with_stream.invoke(full_prompt)
            st.session_state.chat_history.append((prompt_question, response.content))
        st.session_state.trigger_from_prompt = False
        st.session_state.pending_prompt_question = None

    if st.session_state.chat_history:
        st.markdown("---")
        st.subheader("ğŸ’¬ ëŒ€í™” ê¸°ë¡")
        for idx, (q, a) in enumerate(st.session_state.chat_history):
            message(q, is_user=True, key=f"user_{idx}")
            message(a, is_user=False, key=f"bot_{idx}")
